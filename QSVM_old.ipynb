{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "protective-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit import IBMQ\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.aqua import QuantumInstance, aqua_globals\n",
    "from qiskit.aqua.algorithms import QSVM\n",
    "from qiskit.aqua.components.multiclass_extensions import AllPairs, OneAgainstRest\n",
    "from qiskit.aqua.utils import split_dataset_to_data_and_labels, map_label_to_class_name\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 10599\n",
    "aqua_globals.random_seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "expired-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import, process data\n",
    "df = pd.read_csv(\"data/stem_processed_all.csv\")\n",
    "\n",
    "### Subset\n",
    "# df = df.iloc[0:50]\n",
    "\n",
    "LABEL_COL = 'TECH3'\n",
    "\n",
    "x = df.drop(columns=[LABEL_COL])\n",
    "y = df[LABEL_COL]\n",
    "# x = df.drop(columns=['TECH3', 'TECH6'])\n",
    "\n",
    "xtrain_raw, xtest_raw, ytrain, ytest = sklearn.model_selection.train_test_split(x, y, test_size=0.2)\n",
    "# xtrain, xtest, ytrain, ytest = sklearn.model_selection.train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "sel = SelectFromModel(sklearn.ensemble.RandomForestClassifier(n_estimators = 100), \n",
    "                      max_features=5)\n",
    "sel.fit(xtrain_raw, ytrain)\n",
    "support = sel.get_support()\n",
    "newdf_columns = []\n",
    "for column, sup in zip(x.columns, support):\n",
    "    if sup == True:\n",
    "        newdf_columns.append(column)\n",
    "xtrain = xtrain_raw[newdf_columns].copy()\n",
    "xtest = xtest_raw[newdf_columns].copy()\n",
    "\n",
    "feature_dim = len(xtrain.columns)\n",
    "\n",
    "train_inp_3 = {}\n",
    "test_inp_3 = {}\n",
    "train_inp_6 = {}\n",
    "test_inp_6 = {}\n",
    "\n",
    "for i in range(3):\n",
    "    train_inp_3[i] = xtrain[ytrain == i].values\n",
    "    test_inp_3[i] = xtest[ytest == i].values\n",
    "#     train_inp_6[i] = xtrain[ytrain['TECH6'] == i].values\n",
    "#     test_inp_6[i] = xtest[ytest['TECH6'] == i].values\n",
    "\n",
    "temp = [test_inp_3[k] for k in test_inp_3]\n",
    "total_array_3 = np.concatenate(temp)\n",
    "# temp = [test_inp_6[k] for k in test_inp_3]\n",
    "# total_array_6 = np.concatenate(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "joint-crisis",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_accuracy : 0.5\n",
      "test_success_ratio : 0.5\n",
      "predicted_labels : [0 2 2 2 2 2 2 2 2 2]\n",
      "predicted_classes : [0, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "### Classical SVM\n",
    "#################\n",
    "from qiskit.aqua.algorithms import SklearnSVM\n",
    "\n",
    "result = SklearnSVM(train_inp_3, test_inp_3, total_array_3, multiclass_extension=AllPairs()).run()\n",
    "\n",
    "for k,v in result.items():\n",
    "    print(f'{k} : {v}')\n",
    "\n",
    "# print(f'Testing success ratio: {result[\"testing_accuracy\"]}')\n",
    "# print()\n",
    "# print('Prediction from datapoints set:')\n",
    "# print(f'  ground truth: {map_label_to_class_name(datapoints[1], qsvm.label_to_class)}')\n",
    "# print(f'  prediction:   {result[\"predicted_classes\"]}')\n",
    "# predicted_labels = result[\"predicted_labels\"]\n",
    "# print(f'  success rate: {100*np.count_nonzero(predicted_labels == datapoints[1])/len(predicted_labels)}%')\n",
    "\n",
    "# kernel_matrix = result['kernel_matrix_training']\n",
    "# plt.imshow(np.asmatrix(kernel_matrix), interpolation='nearest', origin='upper', cmap='bone_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intense-poker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdmiller/anaconda3/envs/qis/lib/python3.8/site-packages/qiskit/providers/ibmq/ibmqfactory.py:192: UserWarning: Timestamps in IBMQ backend properties, jobs, and job results are all now in local time instead of UTC.\n",
      "  warnings.warn('Timestamps in IBMQ backend properties, jobs, and job results '\n",
      "ibmqfactory.load_account:WARNING:2021-02-25 23:01:51,567: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<IBMQBackend('ibmq_16_melbourne') from IBMQ(hub='ibm-q', group='open', project='main')>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### View available backends\n",
    "\n",
    "# IBMQ.save_account('44a66dd506ef42e540395efa67c2b160558f6425abe98aa5900a5747979902e98add88d240bdd52284ef049ad26aeaefe5dfd167760bf50d6b3777f08e3515c2', overwrite=True)\n",
    "# IBMQ.load_account()\n",
    "\n",
    "provider = IBMQ.get_provider(group='open')\n",
    "provider.backends(filters=lambda x: x.configuration().n_qubits > 5 and not x.configuration().simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job limit reached, waiting for job 603880d917cd9d115f08e313 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 603880d917cd9d115f08e313 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038860701f5e1cc880baf9c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038860801f5e129e10baf9d to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388609a9beb0dfa298b79b to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038860a01f5e18d6a0baf9e to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038860b6ccc8f0a8258db1c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 603886cf17cd9d07d308e33a to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038870117cd9dff5008e33c to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038873417cd9d816a08e33e to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388a3d8511548043d6f6ab to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388a3fe1cffb561272fc24 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388a40ca306ca3592b4a66 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f34ca306c30682b4a85 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f34ca306c30682b4a85 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f34ca306c30682b4a85 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f34ca306c30682b4a85 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f3546d2a038830638a7 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f3546d2a038830638a7 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f3646d2a05a690638a8 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f3773b4f1782b595674 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 60388f386ccc8f42b158db5d to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038937801f5e1850e0bb000 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038937801f5e1850e0bb000 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038937801f5e1850e0bb000 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038937801f5e1850e0bb000 to finish before submitting the next one.\n",
      "Job limit reached, waiting for job 6038937801f5e1850e0bb000 to finish before submitting the next one.\n"
     ]
    }
   ],
   "source": [
    "### Quantum SVM\n",
    "###############\n",
    "\n",
    "### SOLUTION TO UFUNC ERROR ###\n",
    "# In ~/anaconda3/envs/qis/lib/python3.8/site-packages/sklearn/utils/multiclass.py\n",
    "# add            sum_of_confidences = np.real(sum_of_confidences) \n",
    "# just before    sum_of_confidences[:, i] -= confidences[:, k]\n",
    "\n",
    "class_labels = [0,1,2]\n",
    "\n",
    "    # Alternate multiclass extension: OneAgainstRest(), ErrorCorrectingCode(code_size=5), AllPairs()\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=2, entanglement='linear')\n",
    "qsvm = QSVM(feature_map, train_inp_3, test_inp_3, total_array_3, \n",
    "            multiclass_extension=AllPairs())\n",
    "\n",
    "# backend = BasicAer.get_backend('qasm_simulator')\n",
    "backend = provider.get_backend(\"ibmq_16_melbourne\")\n",
    "quantum_instance = QuantumInstance(backend, shots=1024, seed_simulator=seed, \n",
    "                                   seed_transpiler=seed)\n",
    "\n",
    "result = qsvm.run(quantum_instance)\n",
    "\n",
    "for k,v in result.items():\n",
    "    print(f'{k} : {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-lighting",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Visualize results\n",
    "kernel_matrix = result['kernel_matrix_training']\n",
    "plt.imshow(np.asmatrix(kernel_matrix),interpolation='nearest',origin='upper',cmap='bone_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=[''])\n",
    "# label_col = 'TECH3'\n",
    "\n",
    "# labels = set(df[label_col])\n",
    "\n",
    "# data_dict = {}\n",
    "# for label in labels:\n",
    "#     data_dict.update({label:df[df[label_col] == label].drop(columns=[label_col]).to_numpy()})\n",
    "    \n",
    "# data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit.ml.datasets import iris, ad_hoc_data, sample_ad_hoc_data\n",
    "\n",
    "# feature_dim = 4\n",
    "# training_size = 110\n",
    "# test_size = 40\n",
    "\n",
    "# sample_total, training_input, test_input, class_labels = iris(\n",
    "#     training_size=training_size,\n",
    "#     test_size=test_size,\n",
    "#     n=feature_dim)\n",
    "\n",
    "# print(test_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
